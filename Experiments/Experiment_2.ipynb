{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeNHzyynhU_m",
        "outputId": "35ddade0-873e-49f9-8b37-4fbe650f8f63"
      },
      "outputs": [],
      "source": [
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8RkhbE184xr"
      },
      "outputs": [],
      "source": [
        "%cd PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WvVY6CRa9rW",
        "outputId": "9bbccab7-758d-42ff-e2f2-4e7a1271c560"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "\n",
        "# Function to map classifications\n",
        "def mapear_classificacao(texto):\n",
        "    if texto in [0.0, 1.0]:\n",
        "        return texto\n",
        "\n",
        "    texto = unidecode(texto).lower()  # Remove accents and convert to lowercase\n",
        "\n",
        "    if re.search(r'\\bsim\\b', texto):\n",
        "        return 1.0\n",
        "    elif re.search(r'\\bnao\\b', texto):\n",
        "        return 0.0\n",
        "    else:  # For other non -corresponding variations or texts\n",
        "        return 0.0\n",
        "\n",
        "# Explicit choice of 4 files\n",
        "selected_files = [\n",
        "    'Chatgpt_35turbo_datasetName_fewshot_10_prompt_2.csv',\n",
        "    'Maritaca_datasetName_few-shot_10_prompt2_v2.csv',\n",
        "    'Bertimbau_test_datasetName.csv'\n",
        "]\n",
        "\n",
        "# Mapping the names of the model for a name of your choice\n",
        "model_name_mapping = {\n",
        "    'Chatgpt_35turbo_datasetName_fewshot_10_prompt_2': 'ChatGPT 3.5 Turbo Few-Shot - Prompt 2',\n",
        "    'Maritaca_datasetName_few-shot_10_prompt2_v2': 'MariTalk (Sabiá-65B) Few-shot - Prompt 2',\n",
        "    'Bertimbau_test_datasetName': 'BERTimbau Base'\n",
        "}\n",
        "\n",
        "path = 'results'\n",
        "\n",
        "# Load the first CSV\n",
        "first_file = os.path.join(path, selected_files[0])\n",
        "df = pd.read_csv(first_file)\n",
        "final_df = df[['text', 'Toxic']]\n",
        "\n",
        "# Add the Predictions column from the first file to the final dataframe\n",
        "first_column_name = model_name_mapping[os.path.basename(os.path.splitext(selected_files[0])[0])]  # Map the file name to the personalized name\n",
        "df['predictions'] = df['predictions'].apply(mapear_classificacao)\n",
        "final_df[first_column_name] = df['predictions']\n",
        "\n",
        "# Item on the other selected CSV files\n",
        "for file in selected_files[1:]:\n",
        "    file_path = os.path.join(path, file)\n",
        "    temp_df = pd.read_csv(file_path)\n",
        "\n",
        "    # mapearAColunaPredictions\n",
        "    temp_df['predictions'] = temp_df['predictions'].apply(mapear_classificacao)\n",
        "\n",
        "    # Rename the Predictions column according to the mapping\n",
        "    column_name = model_name_mapping[os.path.basename(os.path.splitext(file)[0])]  # Map the file name to the personalized name\n",
        "    final_df[column_name] = temp_df['predictions']\n",
        "\n",
        "#print(final_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQlBT-BcP8P-",
        "outputId": "34c70a96-36ea-4eee-d156-7d47875771b6"
      },
      "outputs": [],
      "source": [
        "!pip install mlxtend\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uBhF3Ee_gnKX",
        "outputId": "3a1620e7-a975-494f-c71a-bb3c41fb9aa6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mapping the names of the model for a name of your choice\n",
        "model_name_mapping = {\n",
        "    'Chatgpt_35turbo_datasetName_fewshot_10_prompt_2': 'ChatGPT 3.5 Turbo Few-Shot - Prompt 2',\n",
        "    'Maritaca_datasetName_few-shot_10_prompt2_v2': 'MariTalk (Sabiá-65B) Few-shot - Prompt 2',\n",
        "    'Bertimbau_test_datasetName': 'BERTimbau Base'\n",
        "}\n",
        "\n",
        "# For each model, calculate the classification report and the confusion matrix\n",
        "for col in final_df.columns:\n",
        "    if col not in ['text', 'Toxic']:\n",
        "        #Obtain the personalized name of the model\n",
        "        modelo_nome = model_name_mapping.get(col, col)  # If you don't find the name mapped, use the original name\n",
        "        print(f\"Modelo: {modelo_nome}\")\n",
        "\n",
        "        # Classification report\n",
        "        print(classification_report(final_df['Toxic'], final_df[col]))\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(final_df['Toxic'], final_df[col])\n",
        "\n",
        "        # Using MLXTEND to plot the confusion matrix\n",
        "        fig, ax = plot_confusion_matrix(conf_mat=cm,\n",
        "                                        show_absolute=True,\n",
        "                                        show_normed=True,\n",
        "                                        colorbar=False,\n",
        "                                        figsize=(10,7),\n",
        "                                        cmap=\"Greys\")\n",
        "        ax.set_title(f'{modelo_nome}')\n",
        "        plt.xlabel('Predicted labels')\n",
        "        plt.ylabel('True labels')\n",
        "        plt.show()\n",
        "\n",
        "        # False positive and false negative rates\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn)  # True positive rate (sensitivity)\n",
        "        fpr = fp / (fp + tn)  # False rate\n",
        "        fnr = fn / (fn + tp)  # False negative rate\n",
        "        tnr = tn / (tn + fp)  # True negative rate (specificity)\n",
        "\n",
        "        print(f\"Taxa de Falso Positivo (FPR): {fpr:.2f}\")\n",
        "        print(f\"Taxa de Falso Negativo (FNR): {fnr:.2f}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRa99hpBzPp-",
        "outputId": "2f9ba59b-2911-4411-d273-315ffed4605a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Mapping the names of the model for a name of your choice\n",
        "model_name_mapping = {\n",
        "    'Chatgpt_35turbo_datasetName_fewshot_10_prompt_2': 'ChatGPT 3.5 Turbo Few-Shot - Prompt 2',\n",
        "    'Maritaca_datasetName_few-shot_10_prompt2_v2': 'MariTalk (Sabiá-65B) Few-shot - Prompt 2',\n",
        "    'Bertimbau_test_datasetName': 'BERTimbau Base'\n",
        "}\n",
        "\n",
        "# List for storing metrics of each model\n",
        "data = []\n",
        "\n",
        "# For each model, calculate the classification report\n",
        "for col in final_df.columns:\n",
        "    if col not in ['text', 'Toxic']:\n",
        "        # Obtain the personalized name of the model\n",
        "        modelo_nome = model_name_mapping.get(col, col)  # If you don't find the name mapped, use the original name\n",
        "        print(f\"Modelo: {modelo_nome}\")\n",
        "\n",
        "        # Classification report\n",
        "        report = classification_report(final_df['Toxic'], final_df[col], output_dict=True)\n",
        "        precision_0, recall_0, f1_0 = report['0.0']['precision'], report['0.0']['recall'], report['0.0']['f1-score']\n",
        "        precision_1, recall_1, f1_1 = report['1.0']['precision'], report['1.0']['recall'], report['1.0']['f1-score']\n",
        "\n",
        "        # Add metrics to the list\n",
        "        data.append([modelo_nome, precision_0, recall_0, f1_0, precision_1, recall_1, f1_1])\n",
        "\n",
        "# Convert List to Dataframe\n",
        "df_metrics = pd.DataFrame(data, columns=['Modelo', 'Precision_NonToxic', 'Recall_NonToxic', 'F1_NonToxic', 'Precision_Toxic', 'Recall_Toxic', 'F1_Toxic'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "Eulr4H6v1r7M",
        "outputId": "90e097a3-d7d7-4a23-f904-609d36779233"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to create radar/spider chart\n",
        "def plot_spider_chart(df, title):\n",
        "    # Number of variables\n",
        "    categories = list(df)[1:]\n",
        "    N = len(categories)\n",
        "\n",
        "    # Angles for each axis\n",
        "    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
        "    angles += angles[:1]\n",
        "\n",
        "    # Initialize the chart\n",
        "    ax = plt.subplot(111, polar=True)\n",
        "\n",
        "    # First axis at the top\n",
        "    ax.set_theta_offset(np.pi / 2)\n",
        "    ax.set_theta_direction(-1)\n",
        "\n",
        "    # Labels for each axis\n",
        "    plt.xticks(angles[:-1], categories)\n",
        "\n",
        "    # Define the label for the Y axis\n",
        "    ax.set_rlabel_position(0)\n",
        "    plt.yticks([0.2, 0.4, 0.6, 0.8], [\"0.2\", \"0.4\", \"0.6\", \"0.8\"], color=\"grey\", size=7)\n",
        "    plt.ylim(0,1)\n",
        "\n",
        "    # Colors for each model\n",
        "    colors = ['b', 'r', 'y', 'g', 'c', 'm', 'k', 'orange']\n",
        "\n",
        "\n",
        "    # Plot metrics for each model\n",
        "    for index, row in df.iterrows():\n",
        "        values = row.drop('Modelo').values.flatten().tolist()\n",
        "        values += values[:1]\n",
        "        ax.plot(angles, values, linewidth=2, linestyle='solid', label=row['Modelo'], color=colors[index % len(colors)])\n",
        "        ax.fill(angles, values, color=colors[index % len(colors)], alpha=0.1)\n",
        "\n",
        "    # Legend\n",
        "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
        "\n",
        "    # Title\n",
        "    plt.title(title, size=11, color='blue', y=1.1)\n",
        "\n",
        "# Plot radar/spider graph for all models on the same chart\n",
        "plt.figure(figsize=(10, 8))\n",
        "plot_spider_chart(df_metrics, \"\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOb53TtNCgVx"
      },
      "source": [
        "## Filter and display the first 20 instances where the zero-shot model made a mistake and the Few-Shot model hit.If there are less than 20 instances that meet this criterion, it will show them all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFc0ADjFCQQ5",
        "outputId": "2f47c0ff-ed38-48df-c79d-d1e2f1cfdd20"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "\n",
        "# Function to map classifications\n",
        "def mapear_classificacao(texto):\n",
        "    if texto in [0.0, 1.0]:\n",
        "        return texto\n",
        "\n",
        "    texto = unidecode(texto).lower()  # Remove accents and convert to lowercase\n",
        "\n",
        "    if re.search(r'\\bsim\\b', texto):\n",
        "        return 1.0\n",
        "    elif re.search(r'\\bnao\\b', texto):\n",
        "        return 0.0\n",
        "    else:  # For other non -corresponding variations or texts\n",
        "        return 0.0\n",
        "\n",
        "# CSVs\n",
        "path_zeroshot = 'Maritaca_datasetName_zeroshot_prompt_2.csv'\n",
        "path_fewshot = 'Maritaca_datasetName_few-shot_10_prompt2_v2.csv'\n",
        "\n",
        "df_zeroshot = pd.read_csv(path_zeroshot)\n",
        "df_fewshot = pd.read_csv(path_fewshot)\n",
        "\n",
        "# Map the prediction column\n",
        "df_zeroshot['predictions'] = df_zeroshot['predictions'].apply(mapear_classificacao)\n",
        "df_fewshot['predictions'] = df_fewshot['predictions'].apply(mapear_classificacao)\n",
        "\n",
        "# Identify instances where the zero-shot model made a mistake and the unce-shot got it right\n",
        "errors_zeroshot_correct_fewshot = df_zeroshot[(df_zeroshot['predictions'] != df_zeroshot['Toxic']) & (df_fewshot['predictions'] == df_zeroshot['Toxic'])]\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Show the first 20 instances\n",
        "print(errors_zeroshot_correct_fewshot[['text', 'Toxic', 'predictions']].head(20))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
