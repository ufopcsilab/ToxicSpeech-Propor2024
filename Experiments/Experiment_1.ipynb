{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b217DaqA8Shk"
      },
      "outputs": [],
      "source": [
        "%cd PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeNHzyynhU_m",
        "outputId": "979c5ffb-89a2-40ff-e569-544669de1063"
      },
      "outputs": [],
      "source": [
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "0WvVY6CRa9rW",
        "outputId": "af676fb6-6205-41d1-8c54-4ebb0803b874"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "\n",
        "# Function to map classifications\n",
        "def mapear_classificacao(texto):\n",
        "    if texto in [0.0, 1.0]:\n",
        "        return texto\n",
        "\n",
        "    texto = unidecode(texto).lower()  # Remove accents and convert to lowercase\n",
        "\n",
        "    if re.search(r'\\bsim\\b', texto):\n",
        "        return 1.0\n",
        "    elif re.search(r'\\bnao\\b', texto):\n",
        "        return 0.0\n",
        "    else:  # For other variations or non-matching texts\n",
        "        return 0.0\n",
        "\n",
        "# Explicit choice of the 4 files\n",
        "selected_files = [\n",
        "    'Chatgpt_35turbo_datasetName_prompt_2_zeroshot.csv',\n",
        "    'Maritaca_datasetName_zeroshot_prompt_1.csv',\n",
        "    'Maritaca_datasetName_zeroshot_prompt_2.csv',\n",
        "    'Bertimbau_test_datasetName.csv'\n",
        "]\n",
        "\n",
        "# Mapping model names to a name of your choice\n",
        "model_name_mapping = {\n",
        "    'Chatgpt_35turbo_datasetName_prompt_2_zeroshot': 'ChatGPT 3.5 Turbo Zero-Shot - Prompt 2',\n",
        "    'Maritaca_datasetName_zeroshot_prompt_1': 'MariTalk (Sabiá-65B) Zero-shot - Prompt 1',\n",
        "    'Maritaca_datasetName_zeroshot_prompt_2': 'MariTalk (Sabiá-65B) Zero-shot - Prompt 2',\n",
        "    'Bertimbau_test_datasetName': 'BERTimbau Base'\n",
        "}\n",
        "\n",
        "path = 'results'\n",
        "\n",
        "# Upload the first CSV\n",
        "first_file = os.path.join(path, selected_files[0])\n",
        "df = pd.read_csv(first_file)\n",
        "final_df = df[['text', 'Toxic']]\n",
        "\n",
        "# Add the predictions column from the first file to the final DataFrame\n",
        "first_column_name = model_name_mapping[os.path.basename(os.path.splitext(selected_files[0])[0])]  # Maps file name to custom name\n",
        "df['predictions'] = df['predictions'].apply(mapear_classificacao)\n",
        "final_df[first_column_name] = df['predictions']\n",
        "\n",
        "# Iterate over the other selected CSV files\n",
        "for file in selected_files[1:]:\n",
        "    file_path = os.path.join(path, file)\n",
        "    temp_df = pd.read_csv(file_path)\n",
        "\n",
        "    # Map the predictions column\n",
        "    temp_df['predictions'] = temp_df['predictions'].apply(mapear_classificacao)\n",
        "\n",
        "    # Rename the predictions column according to the mapping\n",
        "    column_name = model_name_mapping[os.path.basename(os.path.splitext(file)[0])]  # Maps file name to custom name\n",
        "    final_df[column_name] = temp_df['predictions']\n",
        "\n",
        "#print(final_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzPX8pGs0Pg_",
        "outputId": "f5266820-2484-4257-bc4c-5c63e4cb4cba"
      },
      "outputs": [],
      "source": [
        "!pip install mlxtend\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tcogeelaV4UX",
        "outputId": "26c47cba-72dd-42c2-a18b-317ef010c1eb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mapping model names to a name of your choice\n",
        "model_name_mapping = {\n",
        "    'Chatgpt_35turbo_datasetName_prompt_2_zeroshot': 'ChatGPT 3.5 Turbo Zero-Shot - Prompt 2',\n",
        "    'Maritaca_datasetName_zeroshot_prompt_1': 'MariTalk (Sabiá-65B) Zero-shot - Prompt 1',\n",
        "    'Maritaca_datasetName_zeroshot_prompt_2': 'MariTalk (Sabiá-65B) Zero-shot - Prompt 2',\n",
        "    'Bertimbau_test_datasetName': 'BERTimbau Base'\n",
        "}\n",
        "\n",
        "# For each model, calculate the classification report and confusion matrix\n",
        "for col in final_df.columns:\n",
        "    if col not in ['text', 'Toxic']:\n",
        "        # Get custom model name\n",
        "        modelo_nome = model_name_mapping.get(col, col)  # If you can't find the mapped name, use the original name\n",
        "        print(f\"Modelo: {modelo_nome}\")\n",
        "\n",
        "        # Ranking Report\n",
        "        print(classification_report(final_df['Toxic'], final_df[col]))\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(final_df['Toxic'], final_df[col])\n",
        "\n",
        "        # Using mlxtend to plot the confusion matrix\n",
        "        fig, ax = plot_confusion_matrix(conf_mat=cm,\n",
        "                                        show_absolute=True,\n",
        "                                        show_normed=True,\n",
        "                                        colorbar=False,\n",
        "                                        figsize=(10,7),\n",
        "                                        cmap=\"Greys\")\n",
        "        ax.set_title(f'{modelo_nome}')\n",
        "        plt.xlabel('Predicted labels')\n",
        "        plt.ylabel('True labels')\n",
        "        plt.show()\n",
        "\n",
        "        # False positive and false negative rates\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn)  # True positive rate (sensitivity)\n",
        "        fpr = fp / (fp + tn)  # False positive rate\n",
        "        fnr = fn / (fn + tp)  # False negative rate\n",
        "        tnr = tn / (tn + fp)  # True negative rate (specificity)\n",
        "\n",
        "        print(f\"Taxa de Falso Positivo (FPR): {fpr:.2f}\")\n",
        "        print(f\"Taxa de Falso Negativo (FNR): {fnr:.2f}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRa99hpBzPp-",
        "outputId": "c3bd17d9-d1ff-4200-e883-965bd1af69be"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from unidecode import unidecode\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Mapping the names of the model for a name of your choice\n",
        "model_name_mapping = {\n",
        "    'Chatgpt_35turbo_datasetName_prompt_2_zeroshot': 'ChatGPT 3.5 Turbo Zero-Shot - Prompt 2',\n",
        "    'Maritaca_datasetName_zeroshot_prompt_1': 'MariTalk (Sabiá-65B) Zero-shot - Prompt 1',\n",
        "    'Maritaca_datasetName_zeroshot_prompt_2': 'MariTalk (Sabiá-65B) Zero-shot - Prompt 2',\n",
        "    'Bertimbau_test_datasetName': 'BERTimbau Base'\n",
        "}\n",
        "\n",
        "# List for storing metrics of each model\n",
        "data = []\n",
        "\n",
        "# For each model, calculate the classification report\n",
        "for col in final_df.columns:\n",
        "    if col not in ['text', 'Toxic']:\n",
        "        # Obtain the personalized name of the model\n",
        "        modelo_nome = model_name_mapping.get(col, col)  # If you don't find the name mapped, use the original name\n",
        "        print(f\"Modelo: {modelo_nome}\")\n",
        "\n",
        "        # Classification report\n",
        "        report = classification_report(final_df['Toxic'], final_df[col], output_dict=True)\n",
        "        precision_0, recall_0, f1_0 = report['0.0']['precision'], report['0.0']['recall'], report['0.0']['f1-score']\n",
        "        precision_1, recall_1, f1_1 = report['1.0']['precision'], report['1.0']['recall'], report['1.0']['f1-score']\n",
        "\n",
        "        # Add metrics to the list\n",
        "        data.append([modelo_nome, precision_0, recall_0, f1_0, precision_1, recall_1, f1_1])\n",
        "\n",
        "# Convert List to Dataframe\n",
        "df_metrics = pd.DataFrame(data, columns=['Modelo', 'Precision_NonToxic', 'Recall_NonToxic', 'F1_NonToxic', 'Precision_Toxic', 'Recall_Toxic', 'F1_Toxic'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "Eulr4H6v1r7M",
        "outputId": "ea8fbdc0-fb21-48d6-8254-ebcad40fdedd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to create radar/spider chart\n",
        "def plot_spider_chart(df, title):\n",
        "    # Number of variables\n",
        "    categories = list(df)[1:]\n",
        "    N = len(categories)\n",
        "\n",
        "    # Angles for each axis\n",
        "    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
        "    angles += angles[:1]\n",
        "\n",
        "    # Initialize the chart\n",
        "    ax = plt.subplot(111, polar=True)\n",
        "\n",
        "    # First axis at the top\n",
        "    ax.set_theta_offset(np.pi / 2)\n",
        "    ax.set_theta_direction(-1)\n",
        "\n",
        "    # Labels for each axis\n",
        "    plt.xticks(angles[:-1], categories)\n",
        "\n",
        "    # Define the label for the Y axis\n",
        "    ax.set_rlabel_position(0)\n",
        "    plt.yticks([0.2, 0.4, 0.6, 0.8], [\"0.2\", \"0.4\", \"0.6\", \"0.8\"], color=\"grey\", size=7)\n",
        "    plt.ylim(0,1)\n",
        "\n",
        "    # Colors for each model\n",
        "    colors = ['b', 'g', 'r', 'y', 'c', 'm', 'k', 'orange']\n",
        "\n",
        "\n",
        "    # Plot metrics for each model\n",
        "    for index, row in df.iterrows():\n",
        "        values = row.drop('Modelo').values.flatten().tolist()\n",
        "        values += values[:1]\n",
        "        ax.plot(angles, values, linewidth=2, linestyle='solid', label=row['Modelo'], color=colors[index % len(colors)])\n",
        "        ax.fill(angles, values, color=colors[index % len(colors)], alpha=0.1)\n",
        "\n",
        "    # Legend\n",
        "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
        "\n",
        "    # Title\n",
        "    plt.title(title, size=11, color='blue', y=1.1)\n",
        "\n",
        "# Plot radar/spider graph for all models on the same chart\n",
        "plt.figure(figsize=(10, 8))\n",
        "plot_spider_chart(df_metrics, \"\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-dgFvx3V0QAi",
        "outputId": "e2ccbbf4-9bb6-49fe-801c-fb3a8e31b9cb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to create radar/spider chart\n",
        "def plot_spider_chart(df, title):\n",
        "    # Number of variables\n",
        "    categories = list(df)[1:]\n",
        "    N = len(categories)\n",
        "\n",
        "    # Angles for each axis\n",
        "    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
        "    angles += angles[:1]\n",
        "\n",
        "    # Initialize the chart\n",
        "    ax = plt.subplot(111, polar=True)\n",
        "\n",
        "    # First axis at the top\n",
        "    ax.set_theta_offset(np.pi / 2)\n",
        "    ax.set_theta_direction(-1)\n",
        "\n",
        "    # Labels for each axis\n",
        "    plt.xticks(angles[:-1], categories)\n",
        "\n",
        "    # Define the label for the Y axis\n",
        "    ax.set_rlabel_position(0)\n",
        "    plt.yticks([0.2, 0.4, 0.6, 0.8], [\"0.2\", \"0.4\", \"0.6\", \"0.8\"], color=\"grey\", size=7)\n",
        "    plt.ylim(0,1)\n",
        "\n",
        "    # Plot metrics to the model\n",
        "    values = df.iloc[0].drop('Modelo').values.flatten().tolist()\n",
        "    values += values[:1]\n",
        "    ax.plot(angles, values, linewidth=2, linestyle='solid')\n",
        "    ax.fill(angles, values, 'b', alpha=0.1)\n",
        "\n",
        "    # Title\n",
        "    plt.title(title, size=11, color='blue', y=1.1)\n",
        "\n",
        "# Plot radar/spider graph for each model\n",
        "for index, row in df_metrics.iterrows():\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plot_spider_chart(pd.DataFrame(row).T, row['Modelo'])\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bof00X8WiW_c"
      },
      "source": [
        "## Instances in which Bertimbau hit exclusively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "3AG7Aj4xc9do",
        "outputId": "a0ccfb7c-4f4c-483d-e8d5-c0d24c806e87"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Configure so that the dataframe columns are not truncated when displayed\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Mask for instances in which Bertimbau_test_datasetName got it right\n",
        "bertimbau_acertos = final_df['Bertimbau_test_dataseName'] == final_df['labels']\n",
        "\n",
        "# Masks for instances in which other models made mistakes\n",
        "outros_modelos_erros = [final_df[col] != final_df['labels'] for col in final_df.columns if col not in ['text', 'labels', 'Bertimbau_test_datasetName']]\n",
        "\n",
        "# Combine all masks\n",
        "mascara_final = bertimbau_acertos\n",
        "for mascara in outros_modelos_erros:\n",
        "    mascara_final = mascara_final & mascara\n",
        "\n",
        "# Filter the dataframe using the final mask\n",
        "resultados_exclusivos_bertimbau = final_df[mascara_final]\n",
        "\n",
        "print(resultados_exclusivos_bertimbau)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWJd_ANcidwH"
      },
      "source": [
        "## Instances in which maritaca zero-shot hit exclusively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-885FpYXdtN7"
      },
      "outputs": [],
      "source": [
        "# Configure so that the dataframe columns are not truncated when displayed\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Mask for instances where maritaca_datasetName_zeroshot_prompt_2 hit\n",
        "maritaca_acertos = final_df['Maritaca_datasetName_zeroshot_prompt_2'] == final_df['labels']\n",
        "\n",
        "# Masks for instances in which other models made mistakes\n",
        "outros_modelos_erros = [final_df[col] != final_df['labels'] for col in final_df.columns if col not in ['text', 'labels', 'Maritaca_datasetName_zeroshot_prompt_2']]\n",
        "\n",
        "# Combine all masks\n",
        "mascara_final = maritaca_acertos\n",
        "for mascara in outros_modelos_erros:\n",
        "    mascara_final = mascara_final & mascara\n",
        "\n",
        "# Filter the dataframe using the final mask\n",
        "resultados_exclusivos_maritaca = final_df[mascara_final]\n",
        "\n",
        "print(resultados_exclusivos_maritaca)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
